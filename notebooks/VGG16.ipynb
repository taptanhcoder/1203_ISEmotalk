{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import lib ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define spectogram  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_spectrogram(wav_file, xdim=180, ydim=128):\n",
    "    if not wav_file.endswith('.wav'):\n",
    "        raise ValueError(f\"Expected .wav file, but got: {wav_file}\")\n",
    "    \n",
    "    # Load audio\n",
    "    audio, sr = librosa.load(wav_file, sr=None)\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "\n",
    "    # Tạo mel-spectrogram (n_mels=ydim)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=ydim, fmax=8000)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    # Điều chỉnh thời gian (chiều thứ 2) về đúng xdim\n",
    "    # Sử dụng librosa.util.fix_length để pad/truncate\n",
    "    spectrogram = librosa.util.fix_length(spectrogram, size=xdim, axis=1)\n",
    "\n",
    "    # Đảm bảo đúng kích thước (ydim, xdim) → (128, 180)\n",
    "    # spectrogram.shape[0] = ydim, spectrogram.shape[1] = xdim\n",
    "    if spectrogram.shape[0] < ydim:\n",
    "        spectrogram = np.pad(spectrogram, ((0, ydim - spectrogram.shape[0]), (0, 0)), \n",
    "                             mode='constant', constant_values=0)\n",
    "    elif spectrogram.shape[0] > ydim:\n",
    "        spectrogram = spectrogram[:ydim, :]\n",
    "\n",
    "    # Cuối cùng, chuyển từ 2D -> 3D (giả RGB)\n",
    "    spectrogram = np.repeat(spectrogram[..., np.newaxis], 3, axis=-1)\n",
    "\n",
    "    return spectrogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define dataset class ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Sequence):\n",
    "    def __init__(self, file_paths, labels, xdim=180, ydim=180, batch_size=32, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.xdim = xdim\n",
    "        self.ydim = ydim\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_spectrograms = np.array([\n",
    "            wav_to_spectrogram(str(file), self.xdim, self.ydim) \n",
    "            for file in batch_paths\n",
    "        ])\n",
    "\n",
    "        return batch_spectrograms, np.array(batch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.file_paths, self.labels))\n",
    "            np.random.shuffle(temp)\n",
    "            self.file_paths, self.labels = zip(*temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Ravdess = Path(\"../data/RAVDESS_Data\")\n",
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir_name in ravdess_directory_list:\n",
    "    actor_dir = Ravdess / dir_name\n",
    "    if os.path.isdir(actor_dir):\n",
    "        # liệt kê file wav\n",
    "        actor_files = os.listdir(actor_dir)\n",
    "        for file in actor_files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                part = file.split('.')[0]\n",
    "                part = part.split('-')\n",
    "                # part[2] chính là emotion ID\n",
    "                file_emotion.append(int(part[2])) \n",
    "                file_path.append(actor_dir / file)\n",
    "\n",
    "# Tạo dataframe \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Ravdess_df['Emotions'].replace({\n",
    "    1: 'Neutral',\n",
    "    2: 'Calm',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Angry',\n",
    "    6: 'Fear',\n",
    "    7: 'Disgust',\n",
    "    8: 'Surprise'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Ravdess_df[\"Label\"] = label_encoder.fit_transform(Ravdess_df[\"Emotions\"])\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    Ravdess_df, \n",
    "    test_size=0.2, \n",
    "    stratify=Ravdess_df[\"Label\"], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Val size:\", len(val_df))\n",
    "\n",
    "\n",
    "category_labels = label_encoder.classes_\n",
    "num_classes = len(category_labels)\n",
    "print(\"category_labels:\", category_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpectrogramDataset(\n",
    "    file_paths=train_df[\"Path\"].tolist(),\n",
    "    labels=train_df[\"Label\"].tolist(),\n",
    "    xdim=180,\n",
    "    ydim=180,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = SpectrogramDataset(\n",
    "    file_paths=val_df[\"Path\"].tolist(),\n",
    "    labels=val_df[\"Label\"].tolist(),\n",
    "    xdim=180,\n",
    "    ydim=180,\n",
    "    batch_size=16, \n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model architecture ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fine-tuning\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3)\n",
    ")\n",
    "\n",
    "# Freeze ban đầu\n",
    "conv_base.trainable = False\n",
    "\n",
    "# Tạo head\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = keras.applications.vgg16.preprocess_input(inputs)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,              \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_phase1.h5',  \n",
    "    monitor='val_accuracy',  \n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history1.history[\"accuracy\"], label=\"Train Acc (Phase 1)\")\n",
    "plt.plot(history1.history[\"val_accuracy\"], label=\"Val Acc (Phase 1)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tune model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "checkpoint_phase2 = ModelCheckpoint(\n",
    "    'best_model_phase2.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stop, checkpoint_phase2],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history2.history[\"accuracy\"], label=\"Train Acc (Phase 2)\")\n",
    "plt.plot(history2.history[\"val_accuracy\"], label=\"Val Acc (Phase 2)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluate on val_dataset ===\")\n",
    "val_loss, val_acc = model.evaluate(val_dataset, verbose=1)\n",
    "print(f\"Final Validation Loss = {val_loss:.4f}\")\n",
    "print(f\"Final Validation Acc  = {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "for X_batch, y_batch in val_dataset:\n",
    "    preds = model.predict(X_batch)\n",
    "    all_preds.extend(np.argmax(preds, axis=1))\n",
    "    all_labels.extend(y_batch)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=category_labels))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=category_labels)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vgg16_model.h5\")\n",
    "print(\"Model saved to vgg16_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1) Load lại mô hình đã train\n",
    "deploy_model = load_model(\"vgg16_model.h5\")\n",
    "print(\"Loaded model from vgg16_model.h5\")\n",
    "\n",
    "# 2) Chọn 1 file audio .wav bất kỳ để test\n",
    "test_wav = os.path.join(dataset_path, category_labels[0], \"../data/raw_data/sad.MP3\")  \n",
    "# (Ví dụ: thay \"VD1.wav\" bằng tên file cụ thể bạn có)\n",
    "\n",
    "# 3) Ghi nhận thời gian bắt đầu\n",
    "start_time = time.time()\n",
    "\n",
    "# 4) Load file và chuyển thành spectrogram\n",
    "spectrogram = wav_to_spectrogram(test_wav, xdim=180, ydim=180)\n",
    "\n",
    "# 5) Chuẩn bị đầu vào cho mô hình (batch_size=1)\n",
    "spectrogram_input = np.expand_dims(spectrogram, axis=0)  # shape (1, 180, 180, 3)\n",
    "\n",
    "# 6) Mô hình dự đoán\n",
    "pred_prob = deploy_model.predict(spectrogram_input)  # shape (1, num_classes)\n",
    "pred_label_idx = np.argmax(pred_prob, axis=1)[0]\n",
    "pred_label_name = category_labels[pred_label_idx]\n",
    "\n",
    "# 7) Ghi nhận thời gian kết thúc\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 8) In kết quả\n",
    "print(f\"Test file: {test_wav}\")\n",
    "print(f\"Predicted label index = {pred_label_idx}\")\n",
    "print(f\"Predicted label name = {pred_label_name}\")\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
