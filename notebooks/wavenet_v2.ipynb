{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 08:17:08.777050: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745223431.051406   39507 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745223431.694105   39507 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-21 08:17:17.142675: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy as _np\n",
    "if not hasattr(_np, 'complex'):\n",
    "    _np.complex = complex\n",
    "\n",
    "import librosa\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, ZeroPadding1D,\n",
    "    Activation, Multiply, Add,\n",
    "    Softmax, Layer\n",
    ")\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f921352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tham số chung\n",
    "SAMPLE_RATE  = 16000 \n",
    "MAX_DURATION = 3.0                      \n",
    "MAX_SAMPLES  = int(SAMPLE_RATE * MAX_DURATION) \n",
    "BATCH_SIZE   = 8                     \n",
    "EPOCHS       = 50                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6223b9d",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88907596",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_EMOTIONS = ['neutral', 'sad', 'happy', 'angry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading & trimming RAVDESS...\n",
      "Loaded 1440 samples\n"
     ]
    }
   ],
   "source": [
    "EMO_MAP = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "def load_ravdess(path):\n",
    "    X, y = [], []\n",
    "    for fp in glob(os.path.join(path, \"Actor_*\", \"*.wav\")):\n",
    "        code = os.path.basename(fp).split('-')[2]\n",
    "        label = EMO_MAP.get(code)\n",
    "        if label not in TARGET_EMOTIONS:\n",
    "            continue\n",
    "        sig, _ = librosa.load(fp, sr=SAMPLE_RATE)\n",
    "        sig, _ = librosa.effects.trim(sig, top_db=20)\n",
    "        if len(sig) < MAX_SAMPLES:\n",
    "            sig = np.pad(sig, (0, MAX_SAMPLES - len(sig)), 'constant')\n",
    "        else:\n",
    "            sig = sig[:MAX_SAMPLES]\n",
    "        X.append(sig)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_EMO_MAP = {\n",
    "    \"ANG\": \"angry\",\n",
    "    \"DIS\": \"disgust\",\n",
    "    \"FEA\": \"fearful\",\n",
    "    \"HAP\": \"happy\",\n",
    "    \"NEU\": \"neutral\",\n",
    "    \"SAD\": \"sad\"\n",
    "}\n",
    "\n",
    "\n",
    "def load_crema(path, limit=3000):\n",
    "    X, y = [], []\n",
    "    files = glob(os.path.join(path, \"*.wav\"))\n",
    "    count = 0\n",
    "    for fp in files:\n",
    "        if count >= limit:\n",
    "            break\n",
    "        filename = os.path.basename(fp)\n",
    "        parts = filename.split('_')\n",
    "        emo_code = parts[2]\n",
    "        label = CREMA_EMO_MAP.get(emo_code)\n",
    "        if label not in TARGET_EMOTIONS:\n",
    "            continue\n",
    "        sig, _ = librosa.load(fp, sr=SAMPLE_RATE)\n",
    "        sig, _ = librosa.effects.trim(sig, top_db=20)\n",
    "        if len(sig) < MAX_SAMPLES:\n",
    "            sig = np.pad(sig, (0, MAX_SAMPLES - len(sig)), 'constant')\n",
    "        else:\n",
    "            sig = sig[:MAX_SAMPLES]\n",
    "        X.append(sig)\n",
    "        y.append(label)\n",
    "        count += 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAVDESS_PATH = '../data/RAVDESS_Data'\n",
    "CREMA_PATH   = '../data/CREMA_Data'\n",
    "\n",
    "print(\"Loading & trimming RAVDESS...\")\n",
    "X_ravdess, y_ravdess = load_ravdess(RAVDESS_PATH)\n",
    "print(f\"Loaded {X_ravdess.shape[0]} samples from RAVDESS\")\n",
    "\n",
    "print(\"Loading & trimming CREMA-D...\")\n",
    "X_crema, y_crema = load_crema(CREMA_PATH)\n",
    "print(f\"Loaded {X_crema.shape[0]} samples from CREMA-D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24493ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_total = np.concatenate([X_ravdess, X_crema])\n",
    "y_total = np.concatenate([y_ravdess, y_crema])\n",
    "\n",
    "print(f\"Tổng số samples sau khi gộp: {X_total.shape[0]}\")\n",
    "\n",
    "X_total, y_total = shuffle(X_total, y_total, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_onehot = lb.fit_transform(y_total)\n",
    "\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_total, y_onehot, test_size=0.2, stratify=y_total, random_state=42\n",
    ")\n",
    "\n",
    "X_tr = X_tr[..., np.newaxis]\n",
    "X_va = X_va[..., np.newaxis]\n",
    "\n",
    "print(f\"Train set: {X_tr.shape}, Validation set: {X_va.shape}\")\n",
    "print(f\"Số lượng class: {len(lb.classes_)} - {lb.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83487bf0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class WaveNetSER(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 dilations=[1, 2, 4, 8, 16],\n",
    "                 filter_width=2,\n",
    "                 residual_channels=32,\n",
    "                 dilation_channels=64,\n",
    "                 skip_channels=32,\n",
    "                 num_emotions=4,\n",
    "                 use_biases=True):\n",
    "        super(WaveNetSER, self).__init__()\n",
    "\n",
    "        self.dilations = dilations\n",
    "        self.num_emotions = num_emotions\n",
    "        self.use_biases = use_biases\n",
    "\n",
    "        # Causal Convolution Layer\n",
    "        self.causal_conv = tf.keras.layers.Conv1D(\n",
    "            filters=residual_channels,\n",
    "            kernel_size=filter_width,\n",
    "            padding='causal')\n",
    "\n",
    "        # Dilated Residual Blocks\n",
    "        self.residual_blocks = []\n",
    "        for dilation in dilations:\n",
    "            block = {\n",
    "                'conv_filter': tf.keras.layers.Conv1D(\n",
    "                    filters=dilation_channels,\n",
    "                    kernel_size=filter_width,\n",
    "                    dilation_rate=dilation,\n",
    "                    padding='causal'),\n",
    "                'conv_gate': tf.keras.layers.Conv1D(\n",
    "                    filters=dilation_channels,\n",
    "                    kernel_size=filter_width,\n",
    "                    dilation_rate=dilation,\n",
    "                    padding='causal'),\n",
    "                'dense': tf.keras.layers.Conv1D(\n",
    "                    filters=residual_channels,\n",
    "                    kernel_size=1),\n",
    "                'skip': tf.keras.layers.Conv1D(\n",
    "                    filters=skip_channels,\n",
    "                    kernel_size=1),\n",
    "                'batch_norm': tf.keras.layers.BatchNormalization(),\n",
    "                'dropout': tf.keras.layers.Dropout(0.3)\n",
    "            }\n",
    "            self.residual_blocks.append(block)\n",
    "\n",
    "        # Post-processing layers\n",
    "        self.post1 = tf.keras.layers.Conv1D(filters=skip_channels, kernel_size=1)\n",
    "        self.post2 = tf.keras.layers.Conv1D(filters=num_emotions, kernel_size=1)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.causal_conv(inputs)\n",
    "\n",
    "        skip_connections = []\n",
    "        for block in self.residual_blocks:\n",
    "            tanh_out = tf.nn.tanh(block['conv_filter'](x))\n",
    "            sigm_out = tf.nn.sigmoid(block['conv_gate'](x))\n",
    "            z = tanh_out * sigm_out\n",
    "\n",
    "            z = block['batch_norm'](z, training=training)\n",
    "            z = block['dropout'](z, training=training)\n",
    "\n",
    "            skip = block['skip'](z)\n",
    "            skip_connections.append(skip)\n",
    "\n",
    "            x = x + block['dense'](z)\n",
    "\n",
    "        total = tf.add_n(skip_connections)\n",
    "        total = tf.nn.relu(total)\n",
    "        total = self.post1(total)\n",
    "        total = tf.nn.relu(total)\n",
    "        logits = self.post2(total)\n",
    "\n",
    "        # Global Average Pooling để tổng hợp theo thời gian\n",
    "        logits = tf.reduce_mean(logits, axis=1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23515dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "NUM_EMOTIONS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Load Dataset (Giả sử dữ liệu đã chuẩn hóa và padding)\n",
    "train_ds, val_ds = load_data(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = WaveNetSER(num_emotions=NUM_EMOTIONS)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n",
    "\n",
    "# Save model\n",
    "model.save(\"wavenet_ser_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(batch_size=16):\n",
    "    # Giả lập: Dữ liệu input dạng [batch, time_steps, 1]\n",
    "    # Label dạng one-hot [batch, num_emotions]\n",
    "    # Thực tế cần load từ RAVDESS, IEMOCAP,...\n",
    "\n",
    "    def generator():\n",
    "        for _ in range(1000):\n",
    "            yield (tf.random.normal([16000, 1]), tf.one_hot(tf.random.uniform([], 0, 4, dtype=tf.int32), 4))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator, \n",
    "                                             output_types=(tf.float32, tf.float32),\n",
    "                                             output_shapes=((16000,1), (4,)))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset, dataset  # Tạm thời dùng chung train và val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
